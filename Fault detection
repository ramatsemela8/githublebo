

import pandas as pd

df=pd.read_csv("/content/creditcard.csv")
#Display basic information about the dataset

print(df.info())
#Display the first few rows of the dataset

print(df.head())
data = pd.DataFrame(df)

print(data)
missing_values = data.isnull().sum()

print("Missing Values per Column:")

print(missing_values)
df_cleaned = data.dropna()
print(data.head())
print(data.shape)
print(data['Class'].value_counts())
df_cleaned = data.dropna()
print(data.isnull().sum())
#Drop rows with NaN values

data.dropna(inplace=True)
#Impute with mean

data.fillna(data.mean(), inplace=True)
#Impute with median

data.fillna(data.median(), inplace=True)
#Impute with mode (for categorical variables)

data.fillna(data.mode().iloc[0], inplace=True)
#Forward fill

data.fillna(method='ffill', inplace=True)
#Backward fill

data.fillna(method='bfill', inplace=True)
#Linear interpolation

data.interpolate(method='linear', inplace=True)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
#Separate features and target

X = data.drop(['Class'], axis=1)
y = data['Class']
#Split the data into training and testing sets

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
#Standardize the features (important for algorithms like SVM and KNN)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
#Separate features and target

X = data.drop('Class', axis=1)
y = data['Class']
#Scale numerical features

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
#Split data into training and testing sets

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
#Train the model

model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)
#Predict on the test set

y_pred = model.predict(X_test)
#Evaluate performance

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

from imblearn.over_sampling import SMOTE
#Apply SMOTE for class imbalance

sm = SMOTE(random_state=42)
X_res, y_res = sm.fit_resample(X_train, y_train)
#Retrain the model on balanced data

model.fit(X_res, y_res)
y_pred = model.predict(X_test)
#Re-evaluate

print("Accuracy after SMOTE:", accuracy_score(y_test, y_pred))
print("Confusion Matrix after SMOTE:\n", confusion_matrix(y_test, y_pred))
print("Classification Report after SMOTE:\n", classification_report(y_test, y_pred))

